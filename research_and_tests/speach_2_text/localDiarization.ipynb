{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local version of diarization and transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "import whisper\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "audioPath = \"C:/Users/Jose/Desktop/Hackathon/Speech2Text/\"\n",
    "audioName = 'convPepeTrijoMaggi.wav' ## Filtered audio file\n",
    "model_size = \"medium\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available! (Device name: NVIDIA GeForce RTX 3050 Laptop GPU)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_gpu():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU is available! (Device name: {torch.cuda.get_device_name(0)})\")\n",
    "    else:\n",
    "        print(\"GPU is not available. Using CPU.\")\n",
    "\n",
    "check_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local configurations to run the local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from pathlib import Path\n",
    "from pyannote.audio import Pipeline\n",
    "import os\n",
    "\n",
    "def load_pipeline_from_pretrained(path_to_config: str):\n",
    "    path_to_config = Path(path_to_config)\n",
    "\n",
    "    print(f\"Loading pyannote pipeline from {path_to_config}...\")\n",
    "    # the paths in the config are relative to the current working directory\n",
    "    # so we need to change the working directory to the model path\n",
    "    # and then change it back\n",
    "\n",
    "    cwd = Path.cwd().resolve()  # store current working directory\n",
    "\n",
    "    # first .parent is the folder of the config, second .parent is the folder containing the 'models' folder\n",
    "    cd_to = path_to_config.parent.resolve()\n",
    "\n",
    "    print(f\"Changing working directory to {cd_to}\")\n",
    "    os.chdir(cd_to)\n",
    "\n",
    "    pipeline = Pipeline.from_pretrained(path_to_config)\n",
    "\n",
    "    print(f\"Changing working directory back to {cwd}\")\n",
    "    os.chdir(cwd)\n",
    "\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pyannote pipeline from C:\\Users\\Jose\\Desktop\\pyannoteLocal\\config.yaml...\n",
      "Changing working directory to C:\\Users\\Jose\\Desktop\\pyannoteLocal\n",
      "Changing working directory back to C:\\Users\\Jose\\Desktop\\Wilco (Hackathon)\\wilco_radio_assistant\\research_and_tests\\speach_2_text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization at 0x1d44f07b1f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH_TO_CONFIG = \"C:/Users/Jose/Desktop/pyannoteLocal/config.yaml\"\n",
    "pipeline = load_pipeline_from_pretrained(PATH_TO_CONFIG)\n",
    "pipeline.to(torch.device(\"cuda\")) ## Send Pipeline to GPU, CUDA 11.7, torch 2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = audioPath + audioName\n",
    "\n",
    "diarization = pipeline({'uri': 'filename', 'audio': audio_file})\n",
    "\n",
    "segments = []\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    segments.append({\n",
    "        'start': turn.start,\n",
    "        'end': turn.end,\n",
    "        'speaker': speaker\n",
    "    })\n",
    "\n",
    "del pipeline  # release VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = whisper.model(\"small\", device=\"cuda\", compute_type=\"int8\")\n",
    "model = whisper.load_model(\"small\", device=\"cuda\")\n",
    "\n",
    "def transcribe_segment(start, end, audio_path):\n",
    "    y, sr = librosa.load(audio_path, sr=None, offset=start, duration=(end - start))\n",
    "    sf.write(\"temp_segment.wav\", y, sr)\n",
    "    result = model.transcribe(\"temp_segment.wav\")\n",
    "    #print(result)\n",
    "    segments = result['segments']\n",
    "    #print(segments)\n",
    "    counter = 0\n",
    "    for segment in segments:\n",
    "        counter += 1\n",
    "        #print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "        continue\n",
    "        \n",
    "    #print(str(counter) + \" Segments\")\n",
    "    try:\n",
    "        return segment['text']\n",
    "    except:\n",
    "        return \"Unidentified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEAKER_01 [1.47 - 1.99]:  quindi 잘가ぁ는 영상 촬영io\n",
      "SPEAKER_01 [3.27 - 8.65]:  les quería preguntar cómo le fue el día que yo la cagé con la tormenta\n",
      "SPEAKER_00 [16.83 - 18.31]:  Да.\n",
      "SPEAKER_00 [19.04 - 20.72]:  hasta el miércoles y lú\n",
      "SPEAKER_00 [21.59 - 24.71]:  and I want to say\n",
      "SPEAKER_02 [32.08 - 39.19]:  Yo al contrario, tuve luz zorrotos, no se me encortó menos mal, pero mi hermano vinieron hasta mis primas.\n",
      "SPEAKER_02 [39.57 - 40.67]: いめろなー\n",
      "SPEAKER_02 [40.81 - 45.85]:  Te dignos lujos, estamos cargando los colores de todos, de todos, de tus amigos.\n",
      "SPEAKER_00 [46.09 - 48.74]:  ¡Espera, vida del amigo, de la mamá del amigo!\n",
      "SPEAKER_02 [46.09 - 48.96]:  de la vida del amigo, de la mamá del amigo, y todo.\n",
      "SPEAKER_02 [49.3 - 53.57]:  Alguien te lo lo sé como salió pero fue muy chito su paisada porca...\n",
      "SPEAKER_00 [50.18 - 50.74]:  seis失 خصانت cloth\n",
      "SPEAKER_02 [54.42 - 56.39]:  ...interruptor, o sea...\n",
      "SPEAKER_02 [57.04 - 57.8]:  Into farewell?\n",
      "SPEAKER_02 [58.38 - 61.83]:  En chifre nuevo, ser un nuevo que encontrar, y eres impresionante.\n",
      "SPEAKER_01 [66.8 - 68.99]:  y fue terrible porque de hecho\n",
      "SPEAKER_01 [69.91 - 71.83]:  como mientras la casa se inunda.\n",
      "SPEAKER_01 [72.5 - 73.29]:  cortaron la luz\n",
      "SPEAKER_01 [73.79 - 75.98]:  y nosotros sacamos del agua con una bomba de eléctrica.\n",
      "SPEAKER_01 [76.68 - 78.26]:  Entonces claro.\n",
      "SPEAKER_00 [77.82 - 78.06]:  rail\n",
      "SPEAKER_01 [78.5 - 80.43]:  Pasó toda la noche sin luz\n",
      "SPEAKER_00 [79.99 - 80.08]: Unidentified\n",
      "SPEAKER_01 [80.67 - 85.27]:  El agua se empezó a juntar y no se estaba subiendo el nivel del agua a punto de entrar a la casa.\n",
      "SPEAKER_00 [81.54 - 81.96]:  Bye.\n",
      "SPEAKER_01 [85.76 - 87.21]:  Deque é a pracar Poker na cor.\n",
      "SPEAKER_01 [88.24 - 89.89]:  y después con el tiempo.\n",
      "SPEAKER_01 [90.33 - 93.4]:  Decimos ya actuar una omba de vecina que teníamos.\n",
      "SPEAKER_01 [93.69 - 94.92]:  y la Ombro querió por fin.\n",
      "SPEAKER_01 [95.39 - 101.01]:  Y fue terrible, si estuvimos pero medio siglo desarmando la bomba, como viendo la pugilla del motor.\n",
      "SPEAKER_01 [101.52 - 103.76]: ،cción کہ آس بiiہ مہاص FeWhat\n",
      "SPEAKER_01 [105.27 - 107.09]:  어떤\n",
      "SPEAKER_01 [107.67 - 110.74]:  como enladeando y agitando la bomba, como hacer un lado.\n",
      "SPEAKER_01 [111.54 - 113.56]:  यह बर्टिथ यह बर्टिथ,\n",
      "SPEAKER_01 [113.64 - 115.34]:  Probablemente la bugía está como...\n",
      "SPEAKER_01 [115.85 - 117.44]:  האוררMüzik\n",
      "SPEAKER_01 [117.97 - 118.38]:  Thank you.\n",
      "SPEAKER_02 [145.07 - 152.62]:  No, no...\n",
      "SPEAKER_00 [145.61 - 149.09]:  Bueno, ¿no?\n",
      "SPEAKER_02 [153.27 - 154.47]:  ¿Qué se inunda?\n",
      "SPEAKER_01 [158.11 - 163.2]:  Mi pieza está justo al frente de la entrada principal de la casa.\n",
      "SPEAKER_01 [163.42 - 168.28]:  Entonces cuando se entra al agua, el agua como que sigue el camino hacia adelante y llega hasta Mibios, ¿eh?\n",
      "SPEAKER_00 [166.78 - 167.26]:  Thank you.\n",
      "SPEAKER_01 [168.75 - 172.56]:  y cuando nos inundamos yo pongo los pies abajo de mi cama y escucho la música.\n",
      "SPEAKER_01 [172.88 - 172.95]: Unidentified\n",
      "SPEAKER_01 [172.98 - 173.0]: Unidentified\n",
      "SPEAKER_01 [177.73 - 180.98]:  A ver, al final lograron prender la bomba de...\n",
      "SPEAKER_00 [179.16 - 179.36]: Unidentified\n",
      "SPEAKER_00 [181.3 - 184.0]:  Sina funcionó y sacaron el agua.\n",
      "SPEAKER_01 [184.0 - 184.13]: Unidentified\n",
      "SPEAKER_01 [191.35 - 195.46]:  Sí, como te decía, claro, la agitada, la humillaz en un lado y...\n",
      "SPEAKER_01 [196.34 - 197.0]:  Wie funktioniert das?\n",
      "SPEAKER_01 [197.44 - 198.8]:  ur.\n",
      "SPEAKER_00 [199.11 - 199.79]:  you\n",
      "SPEAKER_01 [199.82 - 208.65]:  es gigante y el agua la entraba saliendo segun.\n",
      "SPEAKER_01 [209.53 - 211.72]:  pero antes de eso lo pasábamos por símbolos.\n",
      "SPEAKER_00 [214.39 - 214.68]: Unidentified\n",
      "SPEAKER_01 [214.68 - 220.01]:  te da la pata hinchada, pero...\n",
      "SPEAKER_00 [216.88 - 217.5]: Unidentified\n",
      "SPEAKER_01 [222.89 - 224.86]:  от cut to cut\n",
      "SPEAKER_01 [225.2 - 226.19]:  Thank you.\n",
      "SPEAKER_01 [226.48 - 228.68]:  Cuando una vez que se nos entró el agua\n",
      "SPEAKER_01 [229.18 - 229.57]:  Okay.\n",
      "SPEAKER_01 [229.96 - 232.16]:  como que todo el pueblo de piso flotante que yo...\n",
      "SPEAKER_01 [232.5 - 234.61]:  Hume de abajo, tenia un poco de humedad\n",
      "SPEAKER_00 [232.57 - 232.66]:  Thank you.\n",
      "SPEAKER_00 [232.81 - 232.93]: Unidentified\n",
      "SPEAKER_01 [234.71 - 237.38]:  Hasta el día de hoy abajo el suelo que estamos todos bien.\n",
      "SPEAKER_01 [242.98 - 243.52]:  Bye guys.\n"
     ]
    }
   ],
   "source": [
    "# Transcribe each segment and print\n",
    "output_txt_path = 'LOCALtranscription.txt'\n",
    "with open(output_txt_path, 'w') as f:\n",
    "    f.write(\"Transcription:\\n\")\n",
    "    for segment in segments:\n",
    "        text = transcribe_segment(segment['start'], segment['end'], audio_file)\n",
    "        print(f\"{segment['speaker']} [{round(segment['start'], 2)} - {round(segment['end'], 2)}]: {text}\")\n",
    "        try:\n",
    "            f.write(f\"{segment['speaker']} [{round(segment['start'], 2)} - {round(segment['end'], 2)}]: {text} \\n\")\n",
    "        except:\n",
    "            f.write(\"Unidentified \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
